{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IRE_Major_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AOdu0JplE-F",
        "outputId": "31b36c62-00b0-4911-f071-1624de8768ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu4Kum7qHMk2",
        "outputId": "818926ab-976f-4522-855f-b1d0288a935e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "import copy\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7qD2eEN-pUf"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI4eAooi5wCV"
      },
      "source": [
        "# Loading data files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iplEipRkpm_A"
      },
      "source": [
        "import os\n",
        "import json\n",
        "src_data = dict()\n",
        "path = '/content/drive/My Drive/nela-gt-2019-json/nela-eng-2019'\n",
        "for root, dirs, files in os.walk(path):\n",
        "  for f in sorted(files):\n",
        "      print(\"+ Reading\", f)\n",
        "      with open(os.path.join(root, f)) as fin:\n",
        "          src_data[f] = json.load(fin)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "testQT5e9aJU"
      },
      "source": [
        "import copy\n",
        "new_dict= copy.deepcopy(src_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyqdfuRw51ls"
      },
      "source": [
        "## Taking specific fields of the dataset and discarding the rest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbgFFW1bCuJ1"
      },
      "source": [
        "news_data = {}\n",
        "\n",
        "imp_keys = ['source', 'author', 'content', 'title']\n",
        "for files in src_data:\n",
        "  dummy = {}\n",
        "  dummy_list = []\n",
        "  for entry in src_data[files]:\n",
        "    dummy = {key:entry[key] for key in imp_keys}\n",
        "    dummy_list.append(dummy)\n",
        "  \n",
        "  news_data[files] = dummy_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ0aez4ZJ7c4"
      },
      "source": [
        "# Loading labels file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JaT9fHOHMnt"
      },
      "source": [
        "path = \"/content/drive/My Drive/nela-gt-2019-json/labels.csv\"\n",
        " \n",
        "labels = dict()\n",
        "with open(path) as fin:\n",
        "  fin.readline()\n",
        "  for line in fin:\n",
        "    l = line.strip().split(\",\")\n",
        "    source = l[0]\n",
        "    if l[1] == \"\":\n",
        "      labels[source] = 3\n",
        "      continue\n",
        "    if l[1] == \"1\":\n",
        "      labels[source] = 2\n",
        "    elif l[1] == \"2\":\n",
        "      labels[source] = 1\n",
        "\n",
        "for s in sorted(labels):\n",
        "  print(s,labels[s])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6kwogF5P3J_"
      },
      "source": [
        "path = \"/content/drive/My Drive/nela-gt-2019-json/labels.csv\"\n",
        " \n",
        "labels = dict()\n",
        "with open(path) as fin:\n",
        "  fin.readline()\n",
        "  for line in fin:\n",
        "    l = line.strip().split(\",\")\n",
        "    source = l[0]\n",
        "    if l[1] == \"\":\n",
        "      labels[source] = 3\n",
        "      continue\n",
        "    if l[1] == \"1\":\n",
        "      labels[source] = 2\n",
        "    elif l[1] == \"2\":\n",
        "      labels[source] = 1\n",
        "    else:\n",
        "      labels[source] = 0\n",
        "\n",
        "for s in sorted(labels):\n",
        "  print(s,labels[s])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCogX7eu20vc"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-mTU4ii8e6o"
      },
      "source": [
        "regex1 = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',re.DOTALL)\n",
        "regex2 = re.compile(r'{\\|(.*?)\\|}',re.DOTALL)\n",
        "regex3 = re.compile(r'{{v?cite(.*?)}}',re.DOTALL)\n",
        "regex4 = re.compile(r'[-.,:;_?()\"/\\']',re.DOTALL)\n",
        "regex5 = re.compile(r'\\[\\[file:(.*?)\\]\\]',re.DOTALL)\n",
        "regex6 = re.compile(r\"[~`!@#$%-^*+{\\[}\\]\\|\\\\<>/?]\",re.DOTALL)\n",
        "\n",
        "regex7 = re.compile(r'{{(.*?)}}',re.DOTALL)\n",
        "regex8 = re.compile(r'<(.*?)>',re.DOTALL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGnX7pO36kLZ"
      },
      "source": [
        "no_space = re.compile(\"(&(\\w*))|(@(\\w*))|(\\;)|(\\')|(#)|(\\.)|(\\;)|(\\:)|(\\!)|(\\*)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])\")\n",
        "space = re.compile(\"(\\-)|(\\/)\")\n",
        "single_digits = re.compile(r\"\\b[A-Za-z]\\b\")\n",
        "digits = re.compile(\"\\d+\")\n",
        "extra_spaces = re.compile(r'\\s+')\n",
        "backslash = re.compile(r'\\\\')\n",
        "\n",
        "def preprocess_reviews(content):\n",
        "    \n",
        "    content = [no_space.sub(\"\", line.lower()) for line in content]\n",
        "    content = [digits.sub(\" \", line) for line in content]\n",
        "    content = [backslash.sub(\" \", line) for line in content]\n",
        "    content = [extra_spaces.sub(\" \", line) for line in content]\n",
        "    \n",
        "    return content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCT7zDrm__hn"
      },
      "source": [
        "def preprocess(title):\n",
        "  title = title.lower()\n",
        "  title = regex1.sub(' ', title)\n",
        "  title = regex2.sub(' ', title)\n",
        "  title = regex3.sub(' ', title)\n",
        "  title = regex4.sub(' ', title)\n",
        "  title = regex5.sub(' ', title)\n",
        "  title = regex6.sub(' ', title)\n",
        "  title = regex8.sub(' ', title)\n",
        "  title = digits.sub(' ', title)\n",
        "  title = no_space.sub(' ', title)\n",
        "  title = extra_spaces.sub(' ', title)\n",
        "  title = backslash.sub(' ', title)\n",
        "  return title"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fdcpvsP6HQk"
      },
      "source": [
        "## Stemming using PyStemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI55r6eL9bGG",
        "outputId": "f966a1a9-1069-4f08-c96e-17674e098d52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install PyStemmer\n",
        "import Stemmer\n",
        "stemmer = Stemmer.Stemmer('english')\n",
        "def stem(sentence):\n",
        "  word = stemmer.stemWord(sentence)\n",
        "  return word"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyStemmer in /usr/local/lib/python3.6/dist-packages (2.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3COfQcb6Nnd"
      },
      "source": [
        "## Loading dataset in a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6lO8yaY_Z43"
      },
      "source": [
        "r1 = re.compile(r'\\-')\n",
        "src=[]\n",
        "auth=[]\n",
        "cont=[]\n",
        "title=[]\n",
        "lab=[]\n",
        "imp_keys = ['author', 'content', 'id', 'title']\n",
        "for files in src_data:\n",
        " count = 0\n",
        " print(files)\n",
        " temp = files[0: len(files)-5]\n",
        " temp = r1.sub('', temp)\n",
        " if labels[temp] not in [0, 1]:\n",
        "   continue\n",
        " for entry in src_data[files]:\n",
        "  if count > 500:\n",
        "    break\n",
        "  # src.append(entry['source'])\n",
        "  auth.append(entry['author'])\n",
        "  text = entry['content']\n",
        "  text = preprocess(text)\n",
        "  # text = lemmatize_sentence(text)\n",
        "  text = stem(text)\n",
        "  cont.append(text)\n",
        "  # id.append(entry['id'])\n",
        "  title.append(entry['title'])\n",
        "  # print(files)\n",
        "  temp = files[0: len(files)-5]\n",
        "  temp = r1.sub('', temp)\n",
        "  lab.append(labels[temp])\n",
        "  count += 1\n",
        " \n",
        " \n",
        "df = pd.DataFrame(list(zip(auth, cont, title, lab)), \n",
        " columns =['author', 'content', 'title', 'labels'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LI2GON_W0RK"
      },
      "source": [
        "# 4 Class Classification (Reliable, Unreliable, Mixed, Unlabelled)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX5VZm80KnWM"
      },
      "source": [
        "X = copy.deepcopy(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_orrej5K9LS"
      },
      "source": [
        "y = X['labels']\n",
        "X = X['content']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GSw_L8p6SLD"
      },
      "source": [
        "## Train Test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZJ2iRSI_Z20"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kxCC6s96UgE"
      },
      "source": [
        "## Tfidf Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT6tppze_Z1z"
      },
      "source": [
        "vectorizer = TfidfVectorizer(stop_words = 'english') #, ngram_range=(1, 2))\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwHu8lPi27Fy"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WJ8dEmd8zyB"
      },
      "source": [
        "# Logistic Regression with Tfidf Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqXBsApP8x68",
        "outputId": "92e7a284-5705-4312-dc37-18ce7fc2ad61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "c = [0.001, 0.01, 0.05, 0.5, 0.1]\n",
        "for i in c:\n",
        "    model_lr = LogisticRegression(C = i, max_iter = 1000)\n",
        "    model_lr.fit(X_train, y_train)\n",
        "    y_pred = model_lr.predict(X_test)\n",
        "    accuracy_lr = accuracy_score(y_test, y_pred)\n",
        "    # f1_lr = f1_score(y_test, y_pred, average='micro')\n",
        "    print (\"C = \", i, \" Accuracy: \", accuracy_lr)\n",
        "    # print (\"C = \", i, \" F1 score: \", f1_lr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C =  0.001  Accuracy:  0.3787083645710614\n",
            "C =  0.01  Accuracy:  0.48779051087072933\n",
            "C =  0.05  Accuracy:  0.5860822534004498\n",
            "C =  0.5  Accuracy:  0.661802506158295\n",
            "C =  0.1  Accuracy:  0.6160704723144479\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1xyqgKHAxVv"
      },
      "source": [
        "# SVM with Tfidf Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9U8MZc1AuSA",
        "outputId": "af61c9ab-296c-4699-d9d3-b6aa17df79c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "c = [0.001, 0.01, 0.05, 0.5, 0.1]\n",
        "for i in c:\n",
        "    model_svm = LinearSVC(C=i)\n",
        "    model_svm.fit(X_train, y_train)\n",
        "    y_pred = model_svm.predict(X_test)\n",
        "    accuracy_svm = accuracy_score(y_test, y_pred)\n",
        "    # f1_svm = f1_score(y_test, y_pred)\n",
        "    print (\"C = \", i, \" Accuracy: \", accuracy_svm)\n",
        "    # print (\"C = \", i, \" F1 score: \", f1_svm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C =  0.001  Accuracy:  0.4578022919567313\n",
            "C =  0.01  Accuracy:  0.5997108278890436\n",
            "C =  0.05  Accuracy:  0.6540376994752062\n",
            "C =  0.5  Accuracy:  0.6860072828531648\n",
            "C =  0.1  Accuracy:  0.6700492663596445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR93sW098-Oe"
      },
      "source": [
        "# Logistic Regression with Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6BJI4COC_Io"
      },
      "source": [
        "r1 = re.compile(r'\\-')\n",
        "src=[]\n",
        "auth=[]\n",
        "cont=[]\n",
        "title=[]\n",
        "lab=[]\n",
        "imp_keys = ['author', 'content', 'id', 'title']\n",
        "for files in new_dict:\n",
        " count = 0\n",
        "#  print(files)\n",
        " for entry in new_dict[files]:\n",
        "  if count > 500:\n",
        "    break\n",
        "  # src.append(entry['source'])\n",
        "  auth.append(entry['author'])\n",
        "  text = entry['content']\n",
        "  text = preprocess(text)\n",
        "  # text = lemmatize_sentence(text)\n",
        "  text = stem(text)\n",
        "  cont.append(text)\n",
        "  # id.append(entry['id'])\n",
        "  title.append(entry['title'])\n",
        "  # print(files)\n",
        "  temp = files[0: len(files)-5]\n",
        "  temp = r1.sub('', temp)\n",
        "  lab.append(labels[temp])\n",
        "  count += 1\n",
        " \n",
        " \n",
        "df = pd.DataFrame(list(zip(auth, cont, title, lab)), \n",
        " columns =['author', 'content', 'title', 'labels'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkLcixoKEYwA"
      },
      "source": [
        "X = copy.deepcopy(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGSFKUltEYwZ"
      },
      "source": [
        "y = X['labels']\n",
        "X = X['content']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTu-pikIEYxY"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L00Gm922QX8_"
      },
      "source": [
        "vectorizer = CountVectorizer(stop_words = 'english')\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giSRHWjA_Zvr",
        "outputId": "53525981-c1a1-43cd-e3ae-cba8bd3ef647",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "c = [0.001, 0.01, 0.05, 0.5, 0.1]\n",
        "for i in c:\n",
        "    model_lr = LogisticRegression(C = i, max_iter = 1000)\n",
        "    model_lr.fit(X_train, y_train)\n",
        "    y_pred = model_lr.predict(X_test)\n",
        "    accuracy_lr = accuracy_score(y_test, y_pred)\n",
        "    # f1_lr = f1_score(y_test, y_pred, average='micro')\n",
        "    print (\"C = \", i, \" Accuracy: \", accuracy_lr)\n",
        "    # print (\"C = \", i, \" F1 score: \", f1_lr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C =  0.001  Accuracy:  0.6027944111776448\n",
            "C =  0.01  Accuracy:  0.6393067523489606\n",
            "C =  0.05  Accuracy:  0.6437369164110803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "C =  0.5  Accuracy:  0.6314200866559564\n",
            "C =  0.1  Accuracy:  0.6391607029842753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H-es5BG6fNE"
      },
      "source": [
        "# SVM with Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXnLW8ILi2TW",
        "outputId": "487352a2-7773-47c0-8f29-3e2537ea67e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "c = [0.001, 0.01, 0.05, 0.5, 0.1]\n",
        "for i in c:\n",
        "    model_svm = LinearSVC(C=i)\n",
        "    model_svm.fit(X_train, y_train)\n",
        "    y_pred = model_svm.predict(X_test)\n",
        "    accuracy_svm = accuracy_score(y_test, y_pred)\n",
        "    # f1_svm = f1_score(y_test, y_pred)\n",
        "    print (\"C = \", i, \" Accuracy: \", accuracy_svm)\n",
        "    # print (\"C = \", i, \" F1 score: \", f1_svm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C =  0.001  Accuracy:  0.4578022919567313\n",
            "C =  0.01  Accuracy:  0.5997108278890436\n",
            "C =  0.05  Accuracy:  0.6540376994752062\n",
            "C =  0.5  Accuracy:  0.6860072828531648\n",
            "C =  0.1  Accuracy:  0.6700492663596445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng64SMsgHn9C"
      },
      "source": [
        "# Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-kCUNYkH8CS"
      },
      "source": [
        "vectorizer = TfidfVectorizer(stop_words = 'english')\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXlqFKprkHYv"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "MNB = MultinomialNB().fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Rfcxn5vkHXS",
        "outputId": "891cab85-28ec-4f4b-bb0e-e325c06cf2f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred = MNB.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 2, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xCiGzs9kHUt",
        "outputId": "845d3a14-6d7c-4a1c-9100-76685f02d327",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_mnb = accuracy_score(y_test, y_pred)\n",
        "accuracy_mnb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4638527822403973"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PijFaCvfVkav"
      },
      "source": [
        "# GLOVE embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g3u5Dbrg618"
      },
      "source": [
        "path = \"/content/drive/My Drive/nela-gt-2019-json/labels.csv\"\n",
        "labels = dict()\n",
        "with open(path) as fin:\n",
        "  fin.readline()\n",
        "  for line in fin:\n",
        "    l = line.strip().split(\",\")\n",
        "    source = l[0]\n",
        "    if l[1] == \"\":\n",
        "      labels[source] = 1\n",
        "      continue\n",
        "    if(int(l[1]) != 0):\n",
        "      labels[source]=1\n",
        "      continue\n",
        "    labels[source] = int(l[1])\n",
        " \n",
        "for s in sorted(labels):\n",
        " print(s,labels[s])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR1DGiqJX-H0"
      },
      "source": [
        "r1 = re.compile(r'\\-')\n",
        "src=[]\n",
        "auth=[]\n",
        "cont=[]\n",
        "title=[]\n",
        "lab=[]\n",
        "imp_keys = ['author', 'content', 'id', 'title']\n",
        "for files in src_data:\n",
        " count = 0\n",
        "#  print(files)\n",
        " for entry in src_data[files]:\n",
        "  if count > 20:\n",
        "    break\n",
        "  # src.append(entry['source'])\n",
        "  auth.append(entry['author'])\n",
        "  text = entry['content']\n",
        "  text = preprocess(text)\n",
        "  # text = lemmatize_sentence(text)\n",
        "  text = stem(text)\n",
        "  cont.append(text)\n",
        "  # id.append(entry['id'])\n",
        "  title.append(entry['title'])\n",
        "  # print(files)\n",
        "  temp = files[0: len(files)-5]\n",
        "  temp = r1.sub('', temp)\n",
        "  lab.append(labels[temp])\n",
        "  count += 1\n",
        " \n",
        " \n",
        "df = pd.DataFrame(list(zip(auth, cont, title, lab)), \n",
        " columns =['author', 'content', 'title', 'labels'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flIeD8yiVnGF"
      },
      "source": [
        "import copy\n",
        "X = copy.deepcopy(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQwnQEq2WMVQ"
      },
      "source": [
        "data = []\n",
        "for i in X['content']:\n",
        "  data.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UevnhZjqVNk5"
      },
      "source": [
        "from numpy import array\n",
        "import keras\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "corpus = data\n",
        "# corpus\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "all_words = []\n",
        "for sent in corpus:\n",
        "    tokenize_word = word_tokenize(sent)\n",
        "    for word in tokenize_word:\n",
        "        all_words.append(word)\n",
        "      \n",
        "# all_words\n",
        "unique_words = set(all_words)\n",
        "print(len(unique_words))\n",
        "# print(unique_words)\n",
        "# vocab_length = 20000\n",
        "\n",
        "# embedded_sentences = [one_hot(sent, vocab_length) for sent in corpus]\n",
        "# print(embedded_sentences )\n",
        "\n",
        "word_tokenizer = Tokenizer()\n",
        "word_tokenizer.fit_on_texts(corpus)\n",
        "vocab_length = len(word_tokenizer.word_index) + 1\n",
        "print(\"vocab_length : \",vocab_length)\n",
        "embedded_sentences = word_tokenizer.texts_to_sequences(corpus)\n",
        "# print(embedded_sentences)\n",
        "\n",
        "word_count = lambda sentence: len(word_tokenize(sentence))\n",
        "longest_sentence = max(corpus, key=word_count)\n",
        "length_long_sentence = len(word_tokenize(longest_sentence))\n",
        "padded_sentences = pad_sequences(embedded_sentences, length_long_sentence, padding='post')\n",
        "print(padded_sentences)\n",
        "# y_train = y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4e3cHMmVNhJ",
        "outputId": "a602d8c8-de72-485f-aeaa-33a1b2ab2058",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(type(padded_sentences))\n",
        "padded_sentences.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5256, 12271)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUm4CTumYf38"
      },
      "source": [
        "y = X['labels']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMWNwru6Zqv7"
      },
      "source": [
        "X_train = np.array(padded_sentences[0:4200])\n",
        "X_test = np.array(padded_sentences[4200:])\n",
        "y_train = np.array(y[0:4200])\n",
        "y_test = np.array(y[4200:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0Vv5So7aGTS",
        "outputId": "05a16a30-7ae8-4cfe-85a9-e72c47f15f2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4200, 12271)\n",
            "(1056, 12271)\n",
            "(4200,)\n",
            "(1056,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT6JW7OEaNA2"
      },
      "source": [
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "glove_file = open('/content/drive/My Drive/SMAI_Final_Assignment/Q1/glove.6B/glove.6B.100d.txt', encoding=\"utf8\")\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary [word] = vector_dimensions\n",
        "\n",
        "glove_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HmjHPv6apoS"
      },
      "source": [
        "embedding_matrix = zeros((vocab_length, 100))\n",
        "for word, index in word_tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6E0UyfTa4Sn",
        "outputId": "834553be-6ce0-4cf6-94f0-37226bd5aae1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential()\n",
        "embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\n",
        "model.add(embedding_layer)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 12271, 100)        7757800   \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1227100)           0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 1227101   \n",
            "=================================================================\n",
            "Total params: 8,984,901\n",
            "Trainable params: 1,227,101\n",
            "Non-trainable params: 7,757,800\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "994moMeea-fJ",
        "outputId": "20138458-fa94-406f-e480-a04eb5426361",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train, y_train, epochs=10, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 1.2810 - acc: 0.6445\n",
            "Epoch 2/10\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.3981 - acc: 0.8914\n",
            "Epoch 3/10\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.2022 - acc: 0.9621\n",
            "Epoch 4/10\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.1176 - acc: 0.9755\n",
            "Epoch 5/10\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.0681 - acc: 0.9848\n",
            "Epoch 6/10\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.0451 - acc: 0.9898\n",
            "Epoch 7/10\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.0358 - acc: 0.9926\n",
            "Epoch 8/10\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.0305 - acc: 0.9943\n",
            "Epoch 9/10\n",
            "132/132 [==============================] - 5s 37ms/step - loss: 0.0271 - acc: 0.9952\n",
            "Epoch 10/10\n",
            "132/132 [==============================] - 5s 38ms/step - loss: 0.0234 - acc: 0.9967\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f28340a9eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTKBLEbOc01F"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGLev0w5drim"
      },
      "source": [
        "predictions = []\n",
        "for i in y_pred:\n",
        "    dis1 = 1.0-i[0]\n",
        "    dis2 = i[0]-0.0\n",
        "    ans = 0 if dis1>=dis2 else 1\n",
        "    predictions.append(ans)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e43zLD5ijA1M",
        "outputId": "68f09892-795d-405b-d670-f56d4688d42b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "accuracy_glove = accuracy_score(y_test, predictions)\n",
        "accuracy_glove"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6316287878787878"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8Ntbe0l0OKA"
      },
      "source": [
        "# Summary of the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-7F1jGM0NVO",
        "outputId": "58f1d5ee-5757-4894-baa6-3135816b62c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "a1 = [\"Logistic Regression using TfIdf vectorizer\", accuracy_lr]\n",
        "a2 = [\"SVM using TfIdf vectorizer\", accuracy_svm]\n",
        "a3 = [\"Multinomial Naive Bayes using TfIdf vectorizer\", accuracy_mnb]\n",
        "a4 = [\"Glove 100d embeddings\", accuracy_glove]\n",
        "data = [a1, a2, a3, a4]\n",
        "df = pd.DataFrame(data, columns = ['Model', 'Accuracy'])\n",
        "df\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression using TfIdf vectorizer</td>\n",
              "      <td>0.661803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SVM using TfIdf vectorizer</td>\n",
              "      <td>0.686007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Multinomial Naive Bayes using TfIdf vectorizer</td>\n",
              "      <td>0.463853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Glove 100d embeddings</td>\n",
              "      <td>0.631629</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Model  Accuracy\n",
              "0      Logistic Regression using TfIdf vectorizer  0.661803\n",
              "1                      SVM using TfIdf vectorizer  0.686007\n",
              "2  Multinomial Naive Bayes using TfIdf vectorizer  0.463853\n",
              "3                           Glove 100d embeddings  0.631629"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofv0OQTkGkHc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nq0rV0IdGkYf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbDJiKp-Gk2t"
      },
      "source": [
        "# BINARY CLASSIFICATION MODELS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28qdpMgOUPTG"
      },
      "source": [
        "## We use only reliable and unreliable classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK1PYRHeHU1U"
      },
      "source": [
        "## Train Test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9arq_2svHU1X"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-rvzFSdHU1g"
      },
      "source": [
        "## Tfidf Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q2BljLhHU1i"
      },
      "source": [
        "vectorizer = TfidfVectorizer(stop_words = 'english') #, ngram_range=(1, 2))\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJN91D4eGk2v"
      },
      "source": [
        "# Logistic Regression with Tfidf Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExBPSRxWGk2x",
        "outputId": "aa1bd703-9a3e-485a-c207-3acbcfd31b22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "c = [0.001, 0.01, 0.05, 0.5, 0.1]\n",
        "for i in c:\n",
        "    model_lr = LogisticRegression(C = i, max_iter = 1000)\n",
        "    model_lr.fit(X_train, y_train)\n",
        "    y_pred = model_lr.predict(X_test)\n",
        "    accuracy_lr = accuracy_score(y_test, y_pred)\n",
        "    f1_lr = f1_score(y_test, y_pred, average='micro')\n",
        "    print (\"C = \", i, \" Accuracy: \", accuracy_lr)\n",
        "    print (\"C = \", i, \" F1 score: \", f1_lr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C =  0.001  Accuracy:  0.6498130674737405\n",
            "C =  0.001  F1 score:  0.6498130674737405\n",
            "C =  0.01  Accuracy:  0.6600498486736692\n",
            "C =  0.01  F1 score:  0.6600498486736692\n",
            "C =  0.05  Accuracy:  0.7557414990208297\n",
            "C =  0.05  F1 score:  0.7557414990208297\n",
            "C =  0.5  Accuracy:  0.8396831048602457\n",
            "C =  0.5  F1 score:  0.8396831048602458\n",
            "C =  0.1  Accuracy:  0.7902795086345024\n",
            "C =  0.1  F1 score:  0.7902795086345024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8uOsSb2Gk26"
      },
      "source": [
        "# SVM with Tfidf Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziXI5nPNGk28",
        "outputId": "951a3915-bec0-417b-c5d4-c15e17879967",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "c = [0.001, 0.01, 0.05, 0.5, 0.75, 1]\n",
        "for i in c:\n",
        "    model_svm = LinearSVC(C=i)\n",
        "    model_svm.fit(X_train, y_train)\n",
        "    y_pred = model_svm.predict(X_test)\n",
        "    accuracy_svm = accuracy_score(y_test, y_pred)\n",
        "    f1_svm = f1_score(y_test, y_pred, average='micro')\n",
        "    print (\"C = \", i, \" Accuracy: \", accuracy_svm)\n",
        "    print (\"C = \", i, \" F1 score: \", f1_svm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C =  0.001  Accuracy:  0.6550649813067474\n",
            "C =  0.001  F1 score:  0.6550649813067474\n",
            "C =  0.01  Accuracy:  0.7828912230728147\n",
            "C =  0.01  F1 score:  0.7828912230728147\n",
            "C =  0.05  Accuracy:  0.840484244258501\n",
            "C =  0.05  F1 score:  0.840484244258501\n",
            "C =  0.5  Accuracy:  0.8663877514687556\n",
            "C =  0.5  F1 score:  0.8663877514687556\n",
            "C =  0.75  Accuracy:  0.8654975965818053\n",
            "C =  0.75  F1 score:  0.8654975965818053\n",
            "C =  1  Accuracy:  0.8644294107174648\n",
            "C =  1  F1 score:  0.8644294107174648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brLMIaOdJDvU"
      },
      "source": [
        "# Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_uZq1S6I7Lf"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "MNB = MultinomialNB().fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEV6HJQ9I7L1",
        "outputId": "25f6e6b7-eb86-4f60-a694-add9f54eb818",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred = MNB.predict(X_test)\n",
        "accuracy_mnb = accuracy_score(y_test, y_pred)\n",
        "accuracy_mnb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7334876268470714"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTobY2aNJXn3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6A61X1YJg5S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ek1NRlpUVlg"
      },
      "source": [
        "# Loading the mixed and unlabelled categories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ri-5EkxJg3K"
      },
      "source": [
        "r1 = re.compile(r'\\-')\n",
        "src=[]\n",
        "auth=[]\n",
        "cont=[]\n",
        "title=[]\n",
        "lab=[]\n",
        "imp_keys = ['author', 'content', 'id', 'title']\n",
        "for files in src_data:\n",
        " count = 0\n",
        " temp = files[0: len(files)-5]\n",
        " temp = r1.sub('', temp)\n",
        " if labels[temp] not in {2, 3}:\n",
        "   continue\n",
        " print(files)\n",
        " for entry in src_data[files]:\n",
        "  if count > 500:\n",
        "    break\n",
        "  # src.append(entry['source'])\n",
        "  auth.append(entry['author'])\n",
        "  text = entry['content']\n",
        "  text = preprocess(text)\n",
        "  # text = lemmatize_sentence(text)\n",
        "  text = stem(text)\n",
        "  cont.append(text)\n",
        "  # id.append(entry['id'])\n",
        "  title.append(entry['title'])\n",
        "  # print(files)\n",
        "  temp = files[0: len(files)-5]\n",
        "  temp = r1.sub('', temp)\n",
        "  lab.append(labels[temp])\n",
        "  count += 1\n",
        " \n",
        " \n",
        "df_unlabelled = pd.DataFrame(list(zip(auth, cont, title, lab)), \n",
        " columns =['author', 'content', 'title', 'labels'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TftG-uMBKX2D"
      },
      "source": [
        "X_unlabelled = df_unlabelled['content']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIJriZXtKt7r"
      },
      "source": [
        "X_unlabelled = vectorizer.transform(X_unlabelled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqG9_wnkUjJz"
      },
      "source": [
        "## Predicting the binary classes for Mixed and Unlabelled categories using our trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRfM7t28K01u"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "final_model_svm = LinearSVC(C=0.5)\n",
        "final_model_svm.fit(X_train, y_train)\n",
        "y_pred_unlabelled = model_svm.predict(X_unlabelled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO-dsdcgLOMn",
        "outputId": "c4d351ad-8f43-4508-c63c-08b05984e567",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred_unlabelled"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPJoRANlMrCR"
      },
      "source": [
        "# Appending predicted labels in dataframe.\n",
        "## Our final dataframe would have binary labels (0 : reliable, 1 : unreliable)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANPuuYq6LRZe"
      },
      "source": [
        "r1 = re.compile(r'\\-')\n",
        "src=[]\n",
        "auth=[]\n",
        "cont=[]\n",
        "title=[]\n",
        "lab=[]\n",
        "count1 = 0\n",
        "imp_keys = ['author', 'content', 'title']\n",
        "for files in src_data:\n",
        " count = 0\n",
        " print(files)\n",
        " for entry in src_data[files]:\n",
        "  if count > 500:\n",
        "    break\n",
        "  # src.append(entry['source'])\n",
        "  auth.append(entry['author'])\n",
        "  text = entry['content']\n",
        "  text = preprocess(text)\n",
        "  # text = lemmatize_sentence(text)\n",
        "  text = stem(text)\n",
        "  cont.append(text)\n",
        "  title.append(entry['title'])\n",
        "  # print(files)\n",
        "  temp = files[0: len(files)-5]\n",
        "  temp = r1.sub('', temp)\n",
        "  if labels[temp] in {0, 1}:\n",
        "    lab.append(labels[temp])\n",
        "  else:\n",
        "    lab.append(y_pred_unlabelled[count1])\n",
        "    count1 += 1\n",
        "  count += 1\n",
        " \n",
        " \n",
        "df_final = pd.DataFrame(list(zip(auth, cont, title, lab)), \n",
        " columns =['author', 'content', 'title', 'labels'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE4ktTGtMOeZ",
        "outputId": "5676139f-93af-4b2b-a2e6-173563519e0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "df_final"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>content</th>\n",
              "      <th>title</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21wire</td>\n",
              "      <td>journalist robert inlakesh reported live from ...</td>\n",
              "      <td>WATCH: Londoners Protest UK Government’s Regim...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21wire</td>\n",
              "      <td>if you watch the sci tech news regularly you w...</td>\n",
              "      <td>Digital Wonderland: AI, Transhumanism and Faux...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21wire</td>\n",
              "      <td>yesterday russia and china carried out what it...</td>\n",
              "      <td>South Korean Air Force Fires Warning Shots at ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21wire</td>\n",
              "      <td>kurdish fighters have been used by the us to o...</td>\n",
              "      <td>Will Kurds merge with ISIS as U.S combines pro...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nina Cross</td>\n",
              "      <td>image jeremy hunt and amal clooney campaignin...</td>\n",
              "      <td>What’s Behind Jeremy Hunt’s Choice of Amal Clo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102697</th>\n",
              "      <td>Tyler Durden</td>\n",
              "      <td>a record number of ceos left their positions i...</td>\n",
              "      <td>\"Maybe The Rich See The Writing On The Wall\": ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102698</th>\n",
              "      <td>Tyler Durden</td>\n",
              "      <td>perhaps anticipating the moment iran has to in...</td>\n",
              "      <td>\"Wake-Up Call\" To Europe: Iran Vows Increase O...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102699</th>\n",
              "      <td>Tyler Durden</td>\n",
              "      <td>the swedish government will hand out the equiv...</td>\n",
              "      <td>Swedish Government Grants $175,000 To Fund Dra...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102700</th>\n",
              "      <td>Tyler Durden</td>\n",
              "      <td>french president emmanuel macron s now viral e...</td>\n",
              "      <td>Maybe Just A Coma? Russia Reacts To Macron's \"...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102701</th>\n",
              "      <td>Tyler Durden</td>\n",
              "      <td>labour leader jeremy corbyn and conservative c...</td>\n",
              "      <td>The Battle For The Soul Of Great Britain</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>102702 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              author  ... labels\n",
              "0             21wire  ...      1\n",
              "1             21wire  ...      1\n",
              "2             21wire  ...      1\n",
              "3             21wire  ...      1\n",
              "4         Nina Cross  ...      1\n",
              "...              ...  ...    ...\n",
              "102697  Tyler Durden  ...      1\n",
              "102698  Tyler Durden  ...      1\n",
              "102699  Tyler Durden  ...      1\n",
              "102700  Tyler Durden  ...      1\n",
              "102701  Tyler Durden  ...      1\n",
              "\n",
              "[102702 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FaHEK_pUx_w"
      },
      "source": [
        "# Testing the final model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJffzzr7N0m8"
      },
      "source": [
        "X = df_final['content']\n",
        "y = df_final['labels']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MNr8PGlNv2k"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct5UIh5sNv3A"
      },
      "source": [
        "## Tfidf Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swqgGFqFNv3D"
      },
      "source": [
        "vectorizer = TfidfVectorizer(stop_words = 'english') #, ngram_range=(1, 2))\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqRdSL4rNv3S"
      },
      "source": [
        "# Logistic Regression with Tfidf Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcUmwub1Nv3U",
        "outputId": "7be22f56-6274-4d66-80aa-08a01df9dbb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "c = [0.001, 0.01, 0.05, 0.5, 0.1]\n",
        "for i in c:\n",
        "    model_lr = LogisticRegression(C = i, max_iter = 1000)\n",
        "    model_lr.fit(X_train, y_train)\n",
        "    y_pred = model_lr.predict(X_test)\n",
        "    accuracy_lr = accuracy_score(y_test, y_pred)\n",
        "    f1_lr = f1_score(y_test, y_pred, average='micro')\n",
        "    print (\"C = \", i, \" Accuracy: \", accuracy_lr)\n",
        "    print (\"C = \", i, \" F1 score: \", f1_lr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C =  0.001  Accuracy:  0.6396475341998928\n",
            "C =  0.001  F1 score:  0.6396475341998928\n",
            "C =  0.01  Accuracy:  0.6851175697385716\n",
            "C =  0.01  F1 score:  0.6851175697385716\n",
            "C =  0.05  Accuracy:  0.7840416727520568\n",
            "C =  0.05  F1 score:  0.7840416727520568\n",
            "C =  0.5  Accuracy:  0.8669977118932866\n",
            "C =  0.5  F1 score:  0.8669977118932866\n",
            "C =  0.1  Accuracy:  0.8143712574850299\n",
            "C =  0.1  F1 score:  0.8143712574850299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r95HM_Uhdezr",
        "outputId": "b57e9d51-9fdf-4929-b7c3-e5a13d2c2867",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(82161, 220511)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSkYb4M6dqHF",
        "outputId": "170b67cf-3685-4d56-c4b1-4be0f2278e40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20541, 220511)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOoPF71nNv3k"
      },
      "source": [
        "# SVM with Tfidf Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO8z7SS1Nv3m",
        "outputId": "4113d2df-0478-4903-8ecb-7394e9baa06c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "c = [0.001, 0.01, 0.05, 0.5, 0.75, 1]\n",
        "for i in c:\n",
        "    model_svm = LinearSVC(C=i)\n",
        "    model_svm.fit(X_train, y_train)\n",
        "    y_pred = model_svm.predict(X_test)\n",
        "    accuracy_svm = accuracy_score(y_test, y_pred)\n",
        "    f1_svm = f1_score(y_test, y_pred, average='micro')\n",
        "    print (\"C = \", i, \" Accuracy: \", accuracy_svm)\n",
        "    print (\"C = \", i, \" F1 score: \", f1_svm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C =  0.001  Accuracy:  0.67314152183438\n",
            "C =  0.001  F1 score:  0.67314152183438\n",
            "C =  0.01  Accuracy:  0.8090647972347987\n",
            "C =  0.01  F1 score:  0.8090647972347987\n",
            "C =  0.05  Accuracy:  0.866316148191422\n",
            "C =  0.05  F1 score:  0.866316148191422\n",
            "C =  0.5  Accuracy:  0.9068205053308018\n",
            "C =  0.5  F1 score:  0.9068205053308018\n",
            "C =  0.75  Accuracy:  0.9068205053308018\n",
            "C =  0.75  F1 score:  0.9068205053308018\n",
            "C =  1  Accuracy:  0.9057494766564432\n",
            "C =  1  F1 score:  0.9057494766564432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHiYW7TpTxYz",
        "outputId": "c77e55b0-f2f6-4986-ac79-ca6e09d771e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.94      0.93     13139\n",
            "           1       0.89      0.84      0.87      7402\n",
            "\n",
            "    accuracy                           0.91     20541\n",
            "   macro avg       0.90      0.89      0.90     20541\n",
            "weighted avg       0.91      0.91      0.91     20541\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sUjrCrNcB6z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}